{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ加工・処理・分析ライブラリ\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import scipy as sp\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# 可視化ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# 機械学習ライブラリ\n",
    "import sklearn\n",
    "\n",
    "# 小数第三位まで表示\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インポート\n",
    "import requests, zipfile\n",
    "import io\n",
    "\n",
    "# 自動車価格データを取得\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data'\n",
    "res = requests.get(url).content\n",
    "\n",
    "# 取得したデータをDataFrameオブジェクトとして読み込み\n",
    "auto_df = pd.read_csv(io.StringIO(res.decode('utf-8')), header=None)\n",
    "\n",
    "# データの列にラベルを設定\n",
    "auto_df.columns = ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', \n",
    "                   'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'wheel-base', \n",
    "                   'length', 'width', 'height', 'curb-weight', 'engine-type', \n",
    "                   'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke', \n",
    "                   'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', \n",
    "                   'price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれのカラムに？が何個あるかをカウント\n",
    "auto = auto_df[['price', 'horsepower', 'width', 'height']]\n",
    "auto.isin(['?']).sum()\n",
    "\n",
    "# ?をNaNに置換して、NaNがある行を削除\n",
    "auto = auto.replace('?', np.nan).dropna()\n",
    "\n",
    "auto = auto[['price', 'horsepower', 'width', 'height']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(train):0.733358\n",
      "LinearRegression(test):0.737069\n",
      "Ridge(train):0.733357\n",
      "Ridge(test):0.737420\n",
      "Lasso(train):0.726472\n",
      "Lasso(test):0.762360\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練データとテストデータに分割\n",
    "X = auto.drop('price', axis=1)\n",
    "y = auto['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# モデルの構築と評価\n",
    "linear = LinearRegression()\n",
    "ridge = Ridge(random_state=0)\n",
    "lasso = Lasso(alpha=1000, random_state=0)\n",
    "\n",
    "for model in [linear, ridge, lasso]:\n",
    "    model.fit(X_train, y_train)\n",
    "    print('{}(train):{:.6f}'.format(model.__class__.__name__, model.score(X_train, y_train)))\n",
    "    print('{}(test):{:.6f}'.format(model.__class__.__name__, model.score(X_test, y_test)))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mLasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mprecompute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mselection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cyclic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Linear Model trained with L1 prior as regularizer (aka the Lasso)\n",
       "\n",
       "The optimization objective for Lasso is::\n",
       "\n",
       "    (1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n",
       "\n",
       "Technically the Lasso model is optimizing the same objective function as\n",
       "the Elastic Net with ``l1_ratio=1.0`` (no L2 penalty).\n",
       "\n",
       "Read more in the :ref:`User Guide <lasso>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "alpha : float, optional\n",
       "    Constant that multiplies the L1 term. Defaults to 1.0.\n",
       "    ``alpha = 0`` is equivalent to an ordinary least square, solved\n",
       "    by the :class:`LinearRegression` object. For numerical\n",
       "    reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
       "    Given this, you should use the :class:`LinearRegression` object.\n",
       "\n",
       "fit_intercept : boolean, optional, default True\n",
       "    Whether to calculate the intercept for this model. If set\n",
       "    to False, no intercept will be used in calculations\n",
       "    (e.g. data is expected to be already centered).\n",
       "\n",
       "normalize : boolean, optional, default False\n",
       "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
       "    If True, the regressors X will be normalized before regression by\n",
       "    subtracting the mean and dividing by the l2-norm.\n",
       "    If you wish to standardize, please use\n",
       "    :class:`sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
       "    on an estimator with ``normalize=False``.\n",
       "\n",
       "precompute : True | False | array-like, default=False\n",
       "    Whether to use a precomputed Gram matrix to speed up\n",
       "    calculations. If set to ``'auto'`` let us decide. The Gram\n",
       "    matrix can also be passed as argument. For sparse input\n",
       "    this option is always ``True`` to preserve sparsity.\n",
       "\n",
       "copy_X : boolean, optional, default True\n",
       "    If ``True``, X will be copied; else, it may be overwritten.\n",
       "\n",
       "max_iter : int, optional\n",
       "    The maximum number of iterations\n",
       "\n",
       "tol : float, optional\n",
       "    The tolerance for the optimization: if the updates are\n",
       "    smaller than ``tol``, the optimization code checks the\n",
       "    dual gap for optimality and continues until it is smaller\n",
       "    than ``tol``.\n",
       "\n",
       "warm_start : bool, optional\n",
       "    When set to True, reuse the solution of the previous call to fit as\n",
       "    initialization, otherwise, just erase the previous solution.\n",
       "    See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "positive : bool, optional\n",
       "    When set to ``True``, forces the coefficients to be positive.\n",
       "\n",
       "random_state : int, RandomState instance or None, optional, default None\n",
       "    The seed of the pseudo random number generator that selects a random\n",
       "    feature to update.  If int, random_state is the seed used by the random\n",
       "    number generator; If RandomState instance, random_state is the random\n",
       "    number generator; If None, the random number generator is the\n",
       "    RandomState instance used by `np.random`. Used when ``selection`` ==\n",
       "    'random'.\n",
       "\n",
       "selection : str, default 'cyclic'\n",
       "    If set to 'random', a random coefficient is updated every iteration\n",
       "    rather than looping over features sequentially by default. This\n",
       "    (setting to 'random') often leads to significantly faster convergence\n",
       "    especially when tol is higher than 1e-4.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "coef_ : array, shape (n_features,) | (n_targets, n_features)\n",
       "    parameter vector (w in the cost function formula)\n",
       "\n",
       "sparse_coef_ : scipy.sparse matrix, shape (n_features, 1) |             (n_targets, n_features)\n",
       "    ``sparse_coef_`` is a readonly property derived from ``coef_``\n",
       "\n",
       "intercept_ : float | array, shape (n_targets,)\n",
       "    independent term in decision function.\n",
       "\n",
       "n_iter_ : int | array-like, shape (n_targets,)\n",
       "    number of iterations run by the coordinate descent solver to reach\n",
       "    the specified tolerance.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn import linear_model\n",
       ">>> clf = linear_model.Lasso(alpha=0.1)\n",
       ">>> clf.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n",
       "... # doctest: +NORMALIZE_WHITESPACE\n",
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)\n",
       ">>> print(clf.coef_)\n",
       "[0.85 0.  ]\n",
       ">>> print(clf.intercept_)  # doctest: +ELLIPSIS\n",
       "0.15...\n",
       "\n",
       "See also\n",
       "--------\n",
       "lars_path\n",
       "lasso_path\n",
       "LassoLars\n",
       "LassoCV\n",
       "LassoLarsCV\n",
       "sklearn.decomposition.sparse_encode\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The algorithm used to fit the model is coordinate descent.\n",
       "\n",
       "To avoid unnecessary memory duplication the X argument of the fit method\n",
       "should be directly passed as a Fortran-contiguous numpy array.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\programdata\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     MultiTaskElasticNet\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
